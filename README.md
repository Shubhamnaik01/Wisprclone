# ğŸ™ï¸ Tauri Live Speech-to-Text App (Deepgram)

A cross-platform **desktop speech-to-text application** built using **Tauri + React** with a **Rust backend** and **Deepgram WebSocket API** for real-time transcription.

This project demonstrates **live audio capture**, **streaming transcription**, and **frontendâ€“backend communication** using Tauri commands and events.

---

## âœ¨ Features

- ğŸ§ Live microphone recording
- ğŸ§  Real-time speech-to-text using
- âœï¸ Interim + final transcript handling
- ğŸ“‹ Copy transcript to clipboard
- ğŸ–¥ï¸ Desktop app powered by Tauri (Rust + WebView)

---

## ğŸ§© Tech Stack

**Frontend**

- React
- Vite
- Material UI
- Tailwind CSS

**Backend**

- Rust
- Tauri

**Speech API**

- Deepgram Streaming API (Nova model)

---

## ğŸ“‚ Project Structure

```
root/
â”œâ”€â”€ frontend/              # React frontend
â”‚   â””â”€â”€ src/components/
â”‚       â”œâ”€â”€ Recorder.jsx   # Audio recording & streaming
â”‚       â””â”€â”€ Transcript.jsx # Live transcript display
â”‚
â”œâ”€â”€ src-tauri/              # Rust backend
â”‚   â”œâ”€â”€ src/main.rs        # WebSocket + Deepgram logic
â”‚   â””â”€â”€ .env               # API key (not committed)
â”‚
â””â”€â”€ README.md
```

---

## ğŸ” Environment Setup

Create a `.env` file inside `src-tauri/`:

```env
DEEPGRAM_API_KEY=your_deepgram_api_key_here
```

---

## ğŸš€ How to Run the Project

### 1ï¸âƒ£ Install dependencies

From the project root:

```bash
npm install
```

### 2ï¸âƒ£ Install frontend dependencies

```bash
cd frontend
npm install
```

### 3ï¸âƒ£ Run the Tauri application

From the project root:

```bash
cargo tauri dev
```

This will:

- Start the React frontend
- Launch the Tauri desktop window

---

## ğŸ™ï¸ How It Works

1. User clicks the **mic button**
2. Browser captures microphone audio
3. Audio is converted to **16-bit PCM (48kHz)**
4. Chunks are streamed to Rust via Tauri `invoke`
5. Rust forwards audio to **Deepgram WebSocket**
6. Transcription results are emitted back to React
7. UI displays **final** and **interim** text separately

---

## ğŸ§  Key Design Decisions

- **`useRef` instead of globals** for recorder lifecycle stability
- **WebSocket streaming** for low-latency transcription
- **Event-based communication** from Rust â†’ React
- Clean separation of **interim vs final** transcripts

---

## âš ï¸ Known Limitations

- Interim transcript finalization
  In rare cases, the last few spoken words may remain as interim results if recording is stopped abruptly. This is a known  
  behavior in real-time streaming transcription systems and depends on silence detection and stream closure timing.
- Latency dependency
  Transcription latency may vary based on network conditions, microphone quality, and system performance.
- Accuracy varies with environment
  Background noise, accents, or unclear speech may reduce transcription accuracy, as expected with live speech recognition.
- Single-language focus
  The application is currently optimized for English speech only.

---
